{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-06-30T14:49:45.673763",
          "start_time": "2017-06-30T14:49:44.942772"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "KPdO96NrYMfK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import math\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "wfC8wNoKYMfM"
      },
      "source": [
        "### Create numpy arrays from raw images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-06-30T19:12:50.856213",
          "start_time": "2017-06-30T14:50:02.714072"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "qRd52AjbYMfN"
      },
      "outputs": [],
      "source": [
        "datasets = [\n",
        "    'datasets/abide_imgs',\n",
        "    'datasets/oasis_imgs'\n",
        "]\n",
        "\n",
        "img_size = (128, 128)\n",
        "Xall, Yall = np.array([]), np.array([])\n",
        "number_of_images_total = 0\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(\"Reading data for dataset {}\".format(dataset))\n",
        "    total_images_for_dataset = 0\n",
        "    dataset_folder = os.path.join('.', dataset)\n",
        "    dataset_files = sorted(os.listdir(dataset_folder))\n",
        "    dataset_size = len(dataset_files)\n",
        "    for i in range(0, dataset_size, 2):\n",
        "        number_of_images_total += 1\n",
        "        total_images_for_dataset += 1\n",
        "        full_image = dataset_files[i]\n",
        "        segmented_image = dataset_files[i+1]\n",
        "        if 'abide' in dataset_folder:\n",
        "            full_image, segmented_image = segmented_image, full_image\n",
        "        filename = os.path.splitext(full_image)[0]\n",
        "\n",
        "        # create np array image of full image\n",
        "        tiff_file_path = os.path.join(dataset_folder, full_image)\n",
        "        tiff_image = Image.open(tiff_file_path, 'r').convert('L').resize(img_size)\n",
        "        full_image = np.array(tiff_image)\n",
        "        Xall = np.append(Xall, full_image)\n",
        "\n",
        "        # create np array image of segmented image\n",
        "        tiff_file_path = os.path.join(dataset_folder, segmented_image)\n",
        "        tiff_image = Image.open(tiff_file_path, 'r').convert('L').resize(img_size)\n",
        "        segmented_image = np.array(tiff_image)\n",
        "        segmented_image[segmented_image != 255] = 1.0\n",
        "        segmented_image[segmented_image == 255] = 0.0\n",
        "        Yall = np.append(Yall, segmented_image)\n",
        "\n",
        "        if number_of_images_total % 1000 == 0:\n",
        "            print(\"{} / {} processed!\".format(total_images_for_dataset, dataset_size // 2))\n",
        "    print(\"Dataset {} finished!\".format(dataset))\n",
        "\n",
        "Xall = Xall.reshape(number_of_images_total, *img_size, 1)\n",
        "Yall = Yall.reshape(number_of_images_total, *img_size, 1)\n",
        "\n",
        "print(\"Generated dataset shapes. input: {} ; output: {}\".format(Xall.shape, Yall.shape))\n",
        "\n",
        "joblib.dump((Xall, Yall), 'datasets/all.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "_7nHiCS3YMfO"
      },
      "source": [
        "### Separate train, val and test data and save them on disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-06-30T19:27:51.580430",
          "start_time": "2017-06-30T19:27:49.457360"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "JivYrbiiYMfO"
      },
      "outputs": [],
      "source": [
        "Xall, Yall = joblib.load('datasets/all.pkl')\n",
        "print(Xall.shape)\n",
        "print(Yall.shape)\n",
        "\n",
        "training_percentage = 0.7\n",
        "validation_percentage = 0.1\n",
        "\n",
        "training_set_index = math.floor(Xall.shape[0]*training_percentage)\n",
        "validation_set_index = math.floor(Xall.shape[0]*validation_percentage) + training_set_index\n",
        "\n",
        "# shuffling before training-validation-test slicing\n",
        "ids = np.arange(Xall.shape[0])\n",
        "np.random.shuffle(ids) # shuffle images to avoid bias in training\n",
        "Xall, Yall = Xall[ids], Yall[ids]\n",
        "\n",
        "print(Xall.shape)\n",
        "print(Yall.shape)\n",
        "\n",
        "Xte, yte = Xall[validation_set_index:,:], Yall[validation_set_index:] # X and y for testing\n",
        "# test set is saved on disk. It should NOT be modified. All model evaluations MUST target the same test set.\n",
        "joblib.dump((Xte, yte, {'test_percentage': 1 - training_percentage - validation_percentage }), 'datasets/test.pkl')\n",
        "\n",
        "X_remaining, y_remaining = Xall[:validation_set_index,:], Yall[:validation_set_index] # X and y for training and validation\n",
        "# test and val set are saved on disk. It can be loaded after and be shuffled, cross validated, etc.\n",
        "config = {\n",
        "            'train_percentage': training_percentage,\n",
        "            'training_set_index': training_set_index,\n",
        "            'val_percentage': validation_percentage,\n",
        "            'validation_set_index': validation_set_index\n",
        "         }\n",
        "joblib.dump((X_remaining, y_remaining, config), 'datasets/train-and-val.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Wl5SvJYMfP"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSzn90-dYMfP"
      },
      "outputs": [],
      "source": [
        "X_remaining, Y_remaining, remaining_dataset_desc = joblib.load('datasets/train-and-val.pkl')\n",
        "training_set_index = remaining_dataset_desc['training_set_index']\n",
        "validation_set_index = remaining_dataset_desc['validation_set_index']\n",
        "\n",
        "Xtr, ytr = X_remaining[:training_set_index,:], Y_remaining[:training_set_index] # X and y for training\n",
        "Xva, yva = X_remaining[training_set_index:validation_set_index,:], Y_remaining[training_set_index:validation_set_index] # X and y for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxB9121nYMfQ"
      },
      "outputs": [],
      "source": [
        "augmented_train_dataset_save_file = 'datasets/train-augmented-{}.pkl'\n",
        "\n",
        "txtyrange = range(-1, 1, 1) # translation range for x and y directions\n",
        "loat = [ (tx, ty) for tx in txtyrange for ty in txtyrange ] # list of accepted translations\n",
        "loaa = list(range(-1, 1, 1))\n",
        "foia = len(loat) * len(loaa) # factor of image augmentation\n",
        "print(foia)\n",
        "\n",
        "total_imgs = Xtr.shape[0]\n",
        "increment = 0\n",
        "\n",
        "print(total_imgs*foia)\n",
        "\n",
        "for i in range(total_imgs):\n",
        "    x = Xtr[i]\n",
        "    y = ytr[i]\n",
        "    for (tx, ty) in loat:\n",
        "        input_array = x.reshape(x.shape[0], x.shape[1])\n",
        "        output_array = y.reshape(y.shape[0], y.shape[1])\n",
        "\n",
        "        input_image = Image.fromarray(input_array)\n",
        "        input_image = input_image.transform(input_image.size, Image.AFFINE, (1, 0, tx, 0, 1, ty)) # translated full image\n",
        "\n",
        "        output_image = Image.fromarray(output_array)\n",
        "        output_image = output_image.transform(output_image.size, Image.AFFINE, (1, 0, tx, 0, 1, ty)) # translated full image\n",
        "\n",
        "        for a in loaa:\n",
        "            increment += 1\n",
        "\n",
        "            if increment % 1000 == 0:\n",
        "                print(\"Processed {}/{}\".format(increment, total_imgs*foia))\n",
        "\n",
        "            input_image = input_image.rotate(a, resample=Image.BICUBIC) # rotated trcimg\n",
        "            input_array_augmented = np.array(input_image) # array with pixel values\n",
        "            Xtr = np.append(Xtr, input_array_augmented).reshape(total_imgs+increment, x.shape[0], x.shape[1], x.shape[2])\n",
        "\n",
        "            output_image = output_image.rotate(a, resample=Image.BICUBIC) # rotated trcimg\n",
        "            output_array_augmented = np.array(output_image) # array with pixel values\n",
        "            ytr = np.append(ytr, output_array_augmented).reshape(total_imgs+increment, y.shape[0], y.shape[1], y.shape[2])\n",
        "\n",
        "joblib.dump((Xtr, ytr), augmented_train_dataset_save_file.format(total_imgs*foia))"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "65px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}